{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data reclassification\n",
        "\n",
        "Reclassifying data based on specific criteria is a common task when\n",
        "doing GIS analysis. The purpose of this lesson is to see how we can\n",
        "reclassify values based on some criteria which can be whatever, but\n",
        "typical are related to a logical decision tree.\n",
        "\n",
        "In this lecture we'll look at some traditional use cases to learn\n",
        "classifications.\n",
        "\n",
        "We will use Corine land cover layer from year 2012, and a Population\n",
        "Matrix data from Estonia to classify some features of them based on our\n",
        "own self-made classifier, or using a ready made classifiers that are\n",
        "commonly used e.g. when doing visualizations.\n",
        "\n",
        "The target in this part of the lesson is to:\n",
        "\n",
        "-   classify the bogs into big and small bogs where\n",
        "-   a big bog is a bog that is larger than the average size of all bogs\n",
        "    in our study region\n",
        "-   a small bog  vice versa\n",
        "-   use ready made classifiers from the pysal mapclassify-module to classify\n",
        "    into multiple classes.\n",
        "\n",
        "## Download data\n",
        "\n",
        "Download (and then extract) the dataset zip-package used during this\n",
        "lesson [from this link](../files/data/L4/L4.zip).\n",
        "\n",
        "You should have following Shapefiles in your `L4` folder:\n",
        "\n",
        "``` \n",
        "corine_legend/    corine_tartu.shp            population_admin_units.prj\n",
        "corine_tartu.cpg  corine_tartu.shp.xml        population_admin_units.sbn\n",
        "corine_tartu.dbf  corine_tartu.shx            population_admin_units.sbx\n",
        "corine_tartu.prj  L4.zip                      population_admin_units.shp\n",
        "corine_tartu.sbn  population_admin_units.cpg  population_admin_units.shp.xml\n",
        "corine_tartu.sbx  population_admin_units.dbf  population_admin_units.shx\n",
        "```\n",
        "\n",
        "## Data preparation\n",
        "\n",
        "Before doing any classification, we need to prepare our data a little\n",
        "bit.\n",
        "\n",
        "Let's read the data in and have a look at the columnsand plot our data\n",
        "so that we can see how it looks like on a map."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# some graphical setup in the jupyter notebook\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "mpl.rcParams.update(mpl.rcParamsDefault)\n",
        "plt.style.use('default')\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import os\n",
        "\n",
        "fp = \"../files/data/L4/corine_tartu.shp\"\n",
        "data = gpd.read_file(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see what we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "display(data.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the Land Use in column \"code_12\" is numerical and we\n",
        "don't know right now what that means. So we should at first join the\n",
        "\"clc_legend\" in order to know what the codes mean:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fp_clc = \"../files/data/L4/corine_legend/clc_legend.csv\"\n",
        "data_legend = pd.read_csv(fp_clc, sep=';', encoding='latin1')\n",
        "display(data_legend.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We could now try to merge / join the two dataframes, ideally by the\n",
        "'code_12' column of \"data\" and the \"CLC_CODE\" of \"data_legend\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "display(data.dtypes)\n",
        "display(data_legend.dtypes)\n",
        "\n",
        "# please don't actually do it right now, it might cause extra troubles later\n",
        "# data = data.merge(data_legend, how='inner', left_on='code_12', right_on='CLC_CODE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But if we would try, we will receive an error telling us that the columns are\n",
        "of different data type and therefore can't be used as join-index. So we\n",
        "have to add a column where have the codes in the same type. I am\n",
        "choosing to add a column on \"data\", where we transform the String/Text\n",
        "based \"code_12\" into an integer number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def change_type(row):\n",
        "    code_as_int = int(row['code_12'])\n",
        "    return code_as_int"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data['clc_code_int'] = data.apply(change_type, axis=1)\n",
        "display(data.head(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we are \"casting\" the String-based value, which happens to be a\n",
        "number, to be interpreted as an actula numeric data type. Using the\n",
        "`int()` function. Pandas (and therefore also Geopandas) also provides an\n",
        "in-built function that provides similar functionality\n",
        "[astype()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.astype.html), e.g. like so\n",
        "`data['code_astype_int'] = data['code_12'].astype('int64', copy=True)`\n",
        "\n",
        "Alternatively, Pandas also offers the `pd.to_numeric()` function, e.g. like so\n",
        "`data['code_tonumeric_int'] = pd.to_numeric(data['code_12'], errors='coerce')`\n",
        "\n",
        "Both versions can go wrong if the String cannot be interpreted as a\n",
        "number, and we should be more defensive (more details later, don't\n",
        "worry right now).\n",
        "\n",
        "Now we can merge/join the legend dateframe into our corine landuse\n",
        "dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = data.merge(data_legend, how='inner', left_on='clc_code_int', right_on='CLC_CODE', suffixes=('', '_legend'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have now also added more columns. Let's drop a few, so we can focus\n",
        "on the data we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "selected_cols = ['ID','Remark','Shape_Area','CLC_CODE','LABEL3','RGB','geometry']\n",
        "\n",
        "# Select data\n",
        "data = data[selected_cols]\n",
        "\n",
        "# What are the columns now?\n",
        "display(data.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before we plot, let's check the coordinate system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check coordinate system information\n",
        "print(data.crs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the units are in meters, but ...\n",
        "\n",
        "... geographers will realise that the Corine dataset is in the [ETRS89\n",
        "/ LAEA Europe coordinate system, aka EPSG:3035](http://spatialreference.org/ref/epsg/etrs89-etrs-laea/).\n",
        "Because it is a European dataset it is in the recommended CRS for\n",
        "Europe-wide data. It is a single CRS for all of Europe and predominantly\n",
        "used for statistical mapping at all scales and other purposes where\n",
        "**true area representation is required**.\n",
        "\n",
        "However, being in Estonia and only using an Estonian part of the data,\n",
        "we could consider reprojecting it into the Estonian national grid (aka\n",
        "Estonian Coordinate System of 1997 -> EPSG:3301) before we plot or\n",
        "calculate the area of our bogs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_proj = data.to_crs(epsg=3301)\n",
        "# Calculate the area of bogs\n",
        "data_proj['area'] = data_proj.area\n",
        "\n",
        "# What do we have?\n",
        "display(data_proj['area'].head(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the data and use column 'CLC_CODE' as our color."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_proj.plot(column='CLC_CODE', linewidth=0.05)\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see what kind of values we have in 'code_12' column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(list(data_proj['CLC_CODE'].unique()))\n",
        "print(list(data_proj['LABEL3'].unique()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ee have different kind of land covers in our data. Let's select\n",
        "only bogs from our data. Selecting specific rows from a DataFrame based\n",
        "on some value(s) is easy to do in Pandas / Geopandas using the indexer\n",
        "called `.loc[]`, read more from\n",
        "[here](http://pandas.pydata.org/pandas-docs/stable/indexing.html#different-choices-for-indexing)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Select bogs (i.e. 'Peat bogs' in the data) and make a proper copy\n",
        "# out of our data\n",
        "bogs = data_proj.loc[data_proj['LABEL3'] == 'Peat bogs'].copy()\n",
        "display(bogs.head(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculations in DataFrames\n",
        "\n",
        "Okey now we have our bogs dataset ready. The aim was to classify those\n",
        "bogs into small and big bogs based on **the average size of all bogs**\n",
        "in our study area. Thus, we need to calculate the average size of our\n",
        "bogs.\n",
        "\n",
        "We remember also that the CRS was projected with units in metre, and the\n",
        "calculated values are therefore be in square meters. Let's change those\n",
        "into square kilometers so they are easier to read. Doing calculations in\n",
        "Pandas / Geopandas are easy to do:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bogs['area_km2'] = bogs['area'] / 1000000\n",
        "\n",
        "# What is the mean size of our bogs?\n",
        "l_mean_size = bogs['area_km2'].mean()\n",
        "print(l_mean_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, the size of our bogs seem to be approximately 2.15 square\n",
        "kilometers.\n",
        "\n",
        "But to understand the overall distribution of the different sizes of the\n",
        "bogs, we can use the\n",
        "[histogram](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.hist.html).\n",
        "A histogram shows how the numerical values of a datasets are distributed\n",
        "within the overall data. It shows the frequency of values (how many\n",
        "single \"features\") are within each \"bin\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# explicit plot axes object initialisation\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "bogs['area_km2'].plot.hist(bins=10);\n",
        "\n",
        "# Add title\n",
        "plt.title(\"Bogs area_km2 histogram\")\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-note}\n",
        "It is also easy to calculate e.g. sum or difference between two or more\n",
        "layers (plus all other mathematical operations), e.g.:\n",
        ":::\n",
        "\n",
        "``` python\n",
        "# Sum two columns\n",
        "data['sum_of_columns'] = data['col_1'] + data['col_2']\n",
        "\n",
        "# Calculate the difference of three columns\n",
        "data['difference'] = data['some_column'] - data['col_1'] + data['col_2']\n",
        "```\n",
        "\n",
        "## Classifying data\n",
        "\n",
        "### Creating a custom classifier\n",
        "\n",
        "Let's create a function where we classify the geometries into two\n",
        "classes based on a given `threshold` -parameter. If the area of a\n",
        "polygon is lower than the threshold value (average size of the bog), the\n",
        "output column will get a value 0, if it is larger, it will get a\n",
        "value 1. This kind of classification is often called a\n",
        "[binary classification](https://en.wikipedia.org/wiki/Binary_classification).\n",
        "\n",
        "First we need to create a function for our classification task. This\n",
        "function takes a single row of the GeoDataFrame as input, plus few other\n",
        "parameters that we can use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def binaryClassifier(row, source_col, output_col, threshold):\n",
        "    # If area of input geometry is lower that the threshold value\n",
        "    if row[source_col] < threshold:\n",
        "        # Update the output column with value 0\n",
        "        row[output_col] = 0\n",
        "    # If area of input geometry is higher than the threshold value update with value 1\n",
        "    else:\n",
        "        row[output_col] = 1\n",
        "    # Return the updated row\n",
        "    return row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create an empty column for our classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bogs['small_big'] = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use our custom function by using a Pandas / Geopandas function\n",
        "called `.apply()`. Thus, let's apply our function and do the\n",
        "classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bogs = bogs.apply(binaryClassifier, source_col='area_km2', output_col='small_big', threshold=l_mean_size, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot these bogs and see how they look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bogs.plot(column='small_big', linewidth=0.05, cmap=\"seismic\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It looks like they are correctly classified, good. As a final\n",
        "step let's save the bogs as a file to disk.\n",
        "\n",
        "::: {.callout-note}\n",
        "\n",
        "There is also a way of doing this without a function but with the\n",
        "previous example might be easier to understand how the function works.\n",
        "Doing more complicated set of criteria should definitely be done in a\n",
        "function as it is much more human readable.\n",
        "\n",
        "Let's give a value 0 for small bogs and value 1 for big bogs by using\n",
        "an alternative technique:\n",
        ":::\n",
        "\n",
        "``` python\n",
        "bogs['small_big_alt'] = None\n",
        "bogs.loc[bogs['area_km2'] < l_mean_size, 'small_big_alt'] = 0\n",
        "bogs.loc[bogs['area_km2'] >= l_mean_size, 'small_big_alt'] = 1\n",
        "```\n",
        "\n",
        "::: {.callout-tip}\n",
        "\n",
        "**Task:**\n",
        "\n",
        "Try to change your classification criteria and the LandUse Code/Label selection and visualise the outputs as before.\n",
        ":::\n",
        "\n",
        "### Classification based on common classification schemes\n",
        "\n",
        "[Pysal](https://pysal.org) -module is an\n",
        "extensive Python library including various functions and tools to do\n",
        "spatial data analysis. Its [mapclassify](https://pysal.org/mapclassify/) module also includes all of the\n",
        "most common data classification schemes that are used commonly e.g. when\n",
        "visualizing data. Available map classification schemes in pysal -module\n",
        "are ([see here for more details](https://pysal.org/mapclassify/api.html)):\n",
        "\n",
        "-   BoxPlot: Box_Plot Map Classification\n",
        "-   EqualInterval: Equal Interval Classification\n",
        "-   FisherJenks: Fisher Jenks optimal classifier - mean based\n",
        "-   FisherJenks_Sampled: Fisher Jenks optimal classifier - mean based\n",
        "    using random sample\n",
        "-   HeadTailBreaks: Head/tail Breaks Map Classification for Heavy-tailed\n",
        "    Distributions\n",
        "-   JenksCaspall: Jenks Caspall Map Classification\n",
        "-   JenksCaspallForced: Jenks Caspall Map Classification with forced\n",
        "    movements\n",
        "-   Jenks_CaspallSampled: Jenks Caspall Map Classification using a\n",
        "    random sample\n",
        "-   MaxP: Max_P Map Classification\n",
        "-   MaximumBreaks(: Maximum Breaks Map Classification\n",
        "-   NaturalBreaks: Natural Breaks Map Classification\n",
        "-   Quantiles: Quantile Map Classification\n",
        "-   Percentiles: Percentiles Map Classification\n",
        "-   StdMean: Standard Deviation and Mean Map Classification\n",
        "-   UserDefined: User Specified Binning\n",
        "\n",
        "For this we will use the Adminstrative Units dataset for population. It\n",
        "is in the Estonian \"vald\" level, which compares to the level at\n",
        "municipality. It has the following fields:\n",
        "\n",
        "-   VID, an Id for the \"vald\"\n",
        "-   KOOD, a unique code for the Statistics Board\n",
        "-   NIMI, the name of the municipality\n",
        "-   population, the population, number of people living\n",
        "-   geometry, the polygon for the municpality district border\n",
        "\n",
        "Let's apply one of those schemes into our data and classify the\n",
        "population into 5 classes.\n",
        "\n",
        "**Choosing Number of Classes** -- if you choose too many classes then it\n",
        "requires the map reader to remember too much when viewing the map and it\n",
        "may also make the differentiation of class colors difficult for the map\n",
        "reader. On the other hand, if you choose too few classes, it\n",
        "oversimplifies the data possibly hiding important patterns.\n",
        "Additionally, each class may group dissimilar items together which is in\n",
        "direct opposition of one of the main goals of classification. Typically\n",
        "in cartography three to seven classes are preferred and five is the most\n",
        "common and optimal for most thematic maps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fp = \"../files/data/L4/population_admin_units.shp\"\n",
        "acc = gpd.read_file(fp)\n",
        "display(acc.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, at a close look, we run into the \"numbers as text problem\"\n",
        "again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# data types in the population dataset\n",
        "display(acc.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Therefore, we have to change the column type for population into a\n",
        "numerical data type first:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "\n",
        "def change_type_defensively(row):\n",
        "    try:\n",
        "        return int(row['population'])\n",
        "\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "acc['population_int'] = acc.apply(change_type_defensively, axis=1)\n",
        "display(acc.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we demonstrate a more defensive strategy to convert datatypes. Many\n",
        "operations can cause **Exceptions** and then you can't ignore the\n",
        "problem anymore because your code breaks. But with `try - except` we can\n",
        "catch expected exception (aka crashes) and react appropriately.\n",
        "\n",
        "Pandas (and therefore also Geopandas) also provides an in-built function\n",
        "that provides similar functionality\n",
        "[to_numeric()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_numeric.html#pandas.to_numeric)\n",
        ", e.g. like so\n",
        "`data['code_tonumeric_int'] = pd.to_numeric(data['code_12'], errors='coerce')`.\n",
        "Beware, `to_numeric()` is called as `pandas/pd` function, not on the\n",
        "dataframe.\n",
        "\n",
        "Both versions will at least return a useful NaN value (not_a_number,\n",
        "sort of a nodata value) without crashing. Pandas, Geopandas, numpy and\n",
        "many other Python libraries have some functionality to work with or\n",
        "ignore Nan values without breaking calculations.\n",
        "\n",
        "It would be great to know the actual class ranges for the values. So\n",
        "let's plot a histogram."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "acc[\"population_int\"].plot.hist(bins=100);\n",
        "\n",
        "# Add title\n",
        "plt.title(\"Amount of inhabitants column histogram\")\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can apply a classifier to our data quite similarly as in our\n",
        "previous examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import mapclassify as mc\n",
        "\n",
        "# Define the number of classes\n",
        "n_classes = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The classifier needs to be initialized first with `make()` function that\n",
        "takes the number of desired classes as input parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a Natural Breaks classifier\n",
        "classifier = mc.NaturalBreaks.make(k=n_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we apply the classifier by explicitly providing it a column and\n",
        "then assigning the derived class values to a new column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Classify the data\n",
        "acc['population_classes'] = acc[['population_int']].apply(classifier)\n",
        "\n",
        "# Let's see what we have\n",
        "display(acc.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have added a column to our DataFrame where our input column\n",
        "was classified into 5 different classes (numbers 0-4) based on [Natural\n",
        "Breaks classification](http://wiki.gis.com/wiki/index.php/Jenks_Natural_Breaks_Classification).\n",
        "\n",
        "Great, now we have those values in our population GeoDataFrame. Let's\n",
        "visualize the results and see how they look."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot\n",
        "acc.plot(column=\"population_classes\", linewidth=0, legend=True);\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can make use of a special functionality in Pandas that can better deal with categorical data.\n",
        "After classification, our numrical / integer values are actually categorical data, and we can\n",
        "convert them into a proper categorical data type:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "acc['population_classes'] = acc['population_classes'].astype('category')\n",
        "\n",
        "# this way, the plot legend will not be continuous, but categorical as well\n",
        "acc.plot(column=\"population_classes\", linewidth=0, legend=True, cmap=\"viridis\")\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to get the min() and max() per class group, we use **groupby**\n",
        "again.\n",
        "\n",
        "And in order to add our custom legend info to the plot, we need to\n",
        "employ a bit more of Python's matplotlib magic:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "\n",
        "# legend_dict, a special ordered dictionary (which reliably remembers\n",
        "# order of adding things) that holds our class description and gives it a\n",
        "# colour on the legend (we leave it \"background\" white for now)\n",
        "legend_dict = collections.OrderedDict([])\n",
        "\n",
        "grouped = acc.groupby('population_classes')\n",
        "\n",
        "for cl, valds in grouped:\n",
        "    minv = valds['population_int'].min()\n",
        "    maxv = valds['population_int'].max()\n",
        "    legend_dict.update({\"Class {}: {} - {}\".format(cl, minv, maxv): \"white\"})\n",
        "\n",
        "# Plot preps for several plot into one figure\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# plot the dataframe, with the natural breaks colour scheme\n",
        "acc.plot(ax=ax, column=\"population_classes\", linewidth=0, legend=True, cmap=\"viridis\")\n",
        "\n",
        "# the custom \"patches\" per legend entry of our\n",
        "# additional labels\n",
        "patchList = []\n",
        "for key in legend_dict:\n",
        "    data_key = mpatches.Patch(color=legend_dict[key], label=key)\n",
        "    patchList.append(data_key)\n",
        "\n",
        "# plot the custom legend\n",
        "plt.legend(handles=patchList, loc='lower center', bbox_to_anchor=(0.5, -0.5), ncol=1)\n",
        "\n",
        "# Add title\n",
        "plt.title(\"Amount of inhabitants natural breaks classifier\")\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-tip}\n",
        "\n",
        "**Task:**\n",
        "\n",
        "Try to test different classification methods 'Equal Interval',\n",
        "'Quantiles', and 'Std_Mean' and visualise them.\n",
        ":::\n",
        "\n",
        "![image](../files/img/population_equal_interval.png)\n",
        "\n",
        "![image](../files/img/population_quantiles.png)\n",
        "\n",
        "![image](../files/img/population_std_mean.png)\n",
        "\n",
        "\n",
        "**Download the notebook:**\n",
        "\n",
        "[file:reclassify.ipynb](../files/data/L3/reclassify.ipynb)\n",
        "\n",
        "**Launch in the web/MyBinder:**\n",
        "\n",
        "[![](../files/img/colab-badge.svg)](https://colab.research.google.com/github/LandscapeGeoinformatics/geopy-2023/blob/main/L3/reclassify.ipynb){target=\"blank\"}\n",
        "\n",
        "[![image](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/allixender/testgeo2020b/master?filepath=L3%2Freclassify.ipynb)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}